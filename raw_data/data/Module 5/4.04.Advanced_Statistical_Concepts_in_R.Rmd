---
title: "Advanced Statstical Concepts in R"
author: "Laurie Stevison"
output:
  ioslides_presentation:
    incremental: no
  slidy_presentation:
    incremental: no
---

## Getting Started

For today's class we will be working with the `BodyFat.csv` dataset again. Make an RScript for today's class to save all the code you will be learning. We will cover:

* Practice reading in datasets with more complexity
* Making boxplots of factor data
* Subsetting data in different ways
* Fitting data to statistical models
    + `aov`
    + `glm`

---

## Read in dataset

Our first dataset will be a summary of your results from Lab #6. Based on your comparisons of awk and perl, I have compiled a file "Lab6_Perl_v_Awk.csv". Read the file into an object called "pva":

```{r read data}
setwd("~/Box/Teaching/Comp Bio Fall 2020/Lectures/Module 4")
pva=read.csv(file="Lab6_Perl_v_Awk.csv")
View(pva)
```

Click the data object in the environment tab in RStudio. Notice we have five columns of data: Student, SysRunTime, Perl/Awk, Short/Full, OS. We also have some missing data.

----

## Compare runtime of Perl versus Awk

First, let's compare the distribution of runtimes for each language:

```{r plot-pva}
#plot(pva$Programming.Language.,pva$Sys.Run.Time.)
```

Notice, this plot looks unexpected. That is because we have some missing data and have not coded it correctly.

```{r re-read in data}
pva=read.csv(file="Lab6_Perl_v_Awk.csv",na.strings="na")
#plot(pva$Programming.Language.,pva$Sys.Run.Time.)
```
Now, we have a nice box plot of each dataset.

----

## Basic Summary Statistics

Oh wait, we forgot to run some basic summary statistics on this dataset.

```{r  summary}
summary(pva)
```

Notice the range for mean run time is quite skewed. Let's look at the overall distribution

```{r hist}
hist(pva$Sys.Run.Time.)
```

----

## Remove outliers

Because the majority of our observations are less than 1 and some folks may have put actual run time instead of SysRunTime, let's go ahead and exclude these extreme values and look at the boxplot again:

```{r remove outliers}
pva2=subset(pva,pva$Sys.Run.Time.<=1)
plot(pva2$Programming.Language.,pva2$Sys.Run.Time.,main="Perl versus Awk",xlab="Programming Language",ylab="Sys Time in Seconds")

```

Now we can see the boxes a bit better and while we still have outliers, we've mostly removed the extremes.

-----

## Examine mean in each group

From the boxplots, it looks like Awk is a bit slower than Perl, but let's compare the means of each group:

```{r mean}
mean(pva2$Sys.Run.Time.[pva2$Programming.Language.=="Perl"])
mean(pva2$Sys.Run.Time.[pva2$Programming.Language.=="Awk"])
```

Notice this new way of subsetting from categorical data. 

----

## But didn't we do large and small file sizes? We should look at this a bit closer.

First, let's look at the full size file results:

```{r full size}
full=subset(pva2,pva2$Input.VCF.File.Size.=="Full")
plot(full$Programming.Language.,full$Sys.Run.Time.,main="Perl versus Awk for Full File",xlab="Programming Language",ylab="Sys Time in Seconds")
```

Here, Perl appears faster than Awk, with Python the slowest. But what about for the smaller file when you used `head` to get only the first 10,000 lines?

----

## Smaller file size comparison

Now, let's look at the small size fill results:

```{r small size}
small=subset(pva2,pva2$Input.VCF.File.Size.=="Partial")
plot(small$Programming.Language.,small$Sys.Run.Time.,main="Perl versus Awk for Small File",xlab="Programming Language",ylab="Sys Time in Seconds")
```

Now, Perl and Awk are pretty similar to each other and python is still the slowest. 

----

## Again, let's look at the mean values:

```{r means}
#full file size
mean(full$Sys.Run.Time.[full$Programming.Language.=="Perl"])
mean(full$Sys.Run.Time.[full$Programming.Language.=="Awk"])

#short file size
mean(small$Sys.Run.Time.[small$Programming.Language.=="Perl"])
mean(small$Sys.Run.Time.[small$Programming.Language.=="Awk"])
```

So, the means are different, but are they statistically different?

----

## Is this a statistical difference?

We can test this by using the function `aov` which fits the data to an analysis of variance model. This calls the `lm` function, which is for linear models.

```{r aov}
model_full=aov(full$Sys.Run.Time.~full$Programming.Language.)
model_small=aov(small$Sys.Run.Time.~small$Programming.Language.)

#get AOV Table
summary(model_full)
summary(model_small)
```

Answer: NO! So, don't do anything rash, like choose a particular language based on these data!

*On your own*: We also recorded OS in this dataset, so on your own, compare the sys run time based on OS just like we did here using Programming Language.

----

## Now, let's return to the "BodyFat.csv" dataset

First read in the CSV file:

```{r read data 2}
fat=read.csv(file="BodyFat.csv")
```

----

## Basic Summary Statistics

As we did before, let's look some basic summaries of this new dataset. 

```{r bodyfat}
#statistical summary of data 
summary(fat)
range(fat$WEIGHT)
range(fat$BODYFAT)
```

Summary is a much more comprehensive view of this dataset.

----

## Analyzing a complex dataset

In a previous video, you were asked to analyze this dataset on your own. Each of you did independent correlations of each variable and how it correlated with bodyfat. Because these were non-independent tests, we have to correct for multiple testing. However, a better way to compare how different parameters predict a response variable is to fit the data to a more complex model

```{r glm}
#first, like aov, we will fit a generalized linear model:
fit=glm(BODYFAT~WEIGHT+DENSITY+ADIPOSITY+AGE+HEIGHT+NECK+CHEST+ABDOMEN+HIP+THIGH+KNEE+ANKLE+BICEPS+FOREARM+WRIST,data=fat)

#To see the fit, we will make a summary table
summary(fit)
```

Here, we have built a statsitical model to show how body fat varies due to MULTIPLE parameters in the data. 

We will return to this dataset once more in Module 5 to graphically explore the relationship between Density and Body Fat.